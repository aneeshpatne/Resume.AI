{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anees\\Desktop\\Coding\\llmrepo\\train-LLAMA\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(model_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    device = 'cuda'\n",
    "    model = model.to(device)\n",
    "    return tokenizer, model, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(model, tokenizer, input_text, max_length=200, temperature=0.7, top_p=0.9, device):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    output = model.generate(input[\"input_ids\"], max_length=max_length, temperature=temperature, top_p=top_p, do_sample=True)\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return output_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/Llama-3.2-1B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m tokenizer, model, device \u001b[38;5;241m=\u001b[39m loadModel(model_path)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "model_path = \"D:/Llama-3.2-1B-Instruct\"\n",
    "tokenizer, model, device = loadModel(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a creative prompt for an AI story generator. \"Create a world where time is currency, and people trade years of their lives for material possessions. The main character is a skilled thief who has been tasked with stealing a powerful artifact that can give its owner unimaginable wealth and power. But as they embark on their mission, they begin to question the true cost of their actions and the value of the artifact they seek.\"\n",
      "\n",
      "This prompt encourages the AI to explore themes of time, wealth, and the value of human life, and to create a rich and immersive world with complex characters and plot. Here's a breakdown of the prompt and a possible AI-generated story:\n",
      "\n",
      "**Prompt Breakdown:**\n",
      "\n",
      "* **World-building:** Create a rich, detailed world with a clear history, politics, and societal structure.\n",
      "* **Main Character:** Give the main character a compelling backstory and motivation for their actions.\n",
      "* **Plot:** Set up a clear goal for the main character, and create obstacles and challenges to overcome\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Write a creative prompt for an AI story generator\"\n",
    "output_text = generate_prompt(model, tokenizer, input_text)\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
