{
  "os": "Windows-11-10.0.26100-SP0",
  "python": "CPython 3.12.0",
  "startedAt": "2025-01-05T08:06:54.217581Z",
  "program": "c:\\Users\\anees\\Desktop\\Coding\\llmrepo\\train-LLAMA\\LoRA\\LoRA.ipynb",
  "codePath": "LoRA\\LoRA.ipynb",
  "git": {
    "remote": "https://github.com/aneeshpatne/train-LLAMA.git",
    "commit": "a4371a36d9123d1e1616ca3f696fecc93eab6268"
  },
  "email": "aneeshpatne12@gmail.com",
  "root": "c:\\Users\\anees\\Desktop\\Coding\\llmrepo\\train-LLAMA\\LoRA",
  "host": "ANEESH",
  "executable": "c:\\Users\\anees\\Desktop\\Coding\\llmrepo\\train-LLAMA\\.venv\\Scripts\\python.exe",
  "codePathLocal": "LoRA.ipynb",
  "cpu_count": 8,
  "cpu_count_logical": 16,
  "gpu": "NVIDIA GeForce RTX 4060 Laptop GPU",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "1023010664448",
      "used": "473190957056"
    }
  },
  "memory": {
    "total": "16415322112"
  },
  "cpu": {
    "count": 8,
    "countLogical": 16
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 4060 Laptop GPU",
      "memoryTotal": "8585740288",
      "cudaCores": 3072,
      "architecture": "Ada"
    }
  ],
  "cudaVersion": "12.6"
}