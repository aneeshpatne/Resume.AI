{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0.dev20241211+cu126\n",
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./Llama-3.2-1B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Does Aneesh know NextJs?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You MUST respond with a single word: either \"Yes\" or \"No\". AND keywords no sentences.\n",
    "Do NOT include any other text, explanations, or punctuation.\n",
    "\n",
    "Determine if the following text describes a professional skill, experience, educational achievement, or qualification typically listed on a resume or CV,\n",
    "those skills maybe related to a specific job or industry, or they may be general skills that are applicable to many jobs. define that as the keyword.\n",
    "\n",
    "Examples:\n",
    "1. Text: \"Bachelor of Science in Computer Science from XYZ University.\"\n",
    "   Response: Yes\n",
    "\n",
    "2. Text: \"The weather is sunny today.\"\n",
    "   Response: No\n",
    "\n",
    "3. Text: \"Developed and deployed a machine learning model using Python and TensorFlow, resulting in a 15% improvement in prediction accuracy.\"\n",
    "   Response: Yes\n",
    "\n",
    "4. Text: \"Proficient in Microsoft Office Suite.\"\n",
    "   Response: Yes\n",
    "\n",
    "5. Text: \"Won the local pie-eating contest.\"\n",
    "   Response: No\n",
    "\n",
    "Now classify the following text:\n",
    "\n",
    "Text: \"{input_text}\"\n",
    "Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You MUST respond with ONE of the following categories ONLY: \"Technical Skills\", \"Experience\", \"Project\", \"Education\", or \"Not Related\".\n",
    "YOU MUST also INCLUDE 0 or more than it keywords.\n",
    "Do NOT include any other text, explanations, or punctuation.\n",
    "\n",
    "Your task is to categorize text snippets based on their relevance to a professional resume or CV. The text can be in the form of statements or questions. Consider the context of professional qualifications, work history, and academic background.\n",
    "keywords are the words that are related to the categories.\n",
    "\n",
    "Here's a breakdown of the categories:\n",
    "\n",
    "*   \"Technical Skills\": Text describing specific technical proficiencies (e.g., programming languages, software tools, cloud platforms, frameworks). This includes questions asking about someone's technical skills.\n",
    "*   \"Experience\": Text describing work history, including job titles, responsibilities, accomplishments, internships, and volunteer experience in a professional context.\n",
    "*   \"Project\": Text describing personal, academic, or professional projects that demonstrate skills or experience. Include details about the project's purpose, technologies used, and outcomes.\n",
    "*   \"Education\": Text describing formal education, degrees, certifications, relevant coursework, and academic achievements.\n",
    "*   \"Not Related\": Text that is not relevant to a professional resume or CV (e.g., personal hobbies unrelated to work, general knowledge, philosophical discussions).\n",
    "\n",
    "Examples:\n",
    "\n",
    "1.  Text: \"Proficient in Python, Java, and SQL\"\n",
    "    Response: Technical Skills, Python, Java, SQL\n",
    "2.  Text: \"Worked as a Software Engineer at Google for 3 years, leading a team of 5 developers.\"\n",
    "    Response: Experience, Software Engineer, Google, team leader\n",
    "3.  Text: \"Developed a machine learning model using TensorFlow and Python to predict customer churn, resulting in a 10% reduction.\"\n",
    "    Response: Project, machine learning, TensorFlow, Python, customer churn\n",
    "4.  Text: \"Bachelor of Science in Computer Science from Stanford University, GPA: 3.8\"\n",
    "    Response: Education, Bachelor of Science, Computer Science, Stanford University, GPA\n",
    "5.  Text: \"Does Aneesh know about ReactJS?\"\n",
    "    Response: Technical Skills, ReactJS\n",
    "6.  Text: \"Enjoys playing guitar and watching movies in free time.\"\n",
    "    Response: Not Related, None\n",
    "\n",
    "Now classify the following text:\n",
    "\n",
    "Text: \"{input_text}\"\n",
    "Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=4,         # Limit the response length\n",
    "    temperature=0.1,             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summariser(skill_Name, Skill_details):\n",
    "    print(f\"{skill_Name}: {Skill_details}\")\n",
    "    prompt = f\"\"\"You are an AI assistant providing concise confirmations of skills. \n",
    "You will be given a skill name and its details. Your task is to confirm that the person knows the skill \n",
    "and provide a brief, one-line acknowledgment of the skill itself and also provide VERY SMALL description of the skill.\n",
    "\n",
    "Skill: {skill_Name}\n",
    "Details: {Skill_details}\n",
    "\n",
    "Response format example: 'Yes, Aneesh knows [Skill Name]. [One-line description of the skill].'\n",
    "\n",
    "Provide a concise response:\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,         # Limit the response length\n",
    "    temperature=0.1,             \n",
    ")\n",
    "    new_tokens = output[0][inputs.input_ids.shape[1]:]\n",
    "    response = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    print(response)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_skills_list = set([\"Python\", \"JavaScript\", \"React\", \"Node.js\", \"AWS\", \"Docker\", \"NextJS\"])\n",
    "def technical_skill_summariser(skills):\n",
    "    for skill in skills:\n",
    "        if skill.strip() in technical_skills_list:\n",
    "            summariser(\"Technical Skills\", skill.strip())\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Skills: Next\n",
      " \n",
      "Aneesh knows Python. Python is a high-level, interpreted programming language.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_tokens = output[0][inputs.input_ids.shape[1]:]\n",
    "response = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "respose_split = response.strip().split(\",\")\n",
    "if respose_split[0] == \"Technical Skills\":\n",
    "    technical_skill_summariser(respose_split[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
