{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anees\\Desktop\\Coding\\llmrepo\\train-LLAMA\\.venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, clear_output\n",
    "from textwrap import wrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(os.getenv(\"PINECONE_KEY\"))\n",
    "index = pc.Index(\"resume-index-full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_chatbot(user_messsage, conversation_history):\n",
    "    try:\n",
    "        conversation_history.append(user_messsage)\n",
    "        response_stream = client.chat.completions.create(\n",
    "            model=\"mistral:latest\",\n",
    "            messages=conversation_history,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        output_box = \"\" \n",
    "        for chunk in response_stream:\n",
    "            if chunk.choices and len(chunk.choices) > 0:\n",
    "                delta = chunk.choices[0].delta\n",
    "                if delta and delta.content:\n",
    "                    output_box += delta.content  \n",
    "                    clear_output(wait=True)  \n",
    "                    display(output_box)\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": output_box})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_chat(query):\n",
    "    # Encode query and retrieve relevant chunks as before\n",
    "    embedded_query = model.encode(query).tolist()\n",
    "    retrieved_chunks = index.query(\n",
    "        vector=embedded_query,\n",
    "        top_k=5,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    dic = defaultdict(list)\n",
    "    for match in retrieved_chunks.matches:\n",
    "        section = match.metadata.get('section', 'Unknown Section')\n",
    "        text = match.metadata.get('text', '')\n",
    "        dic[section].append(text)\n",
    "\n",
    "    # Build chunks_text for prompt\n",
    "    chunks_text = \"\"\n",
    "    for section, texts in dic.items():\n",
    "        chunks_text += f\"{section}:\\n\"\n",
    "        for text in texts:\n",
    "            chunks_text += f\"{text}\\n\\n\"\n",
    "\n",
    "    # Construct final prompt using improved logic\n",
    "    prompt_header = (\n",
    "        \"You are Chotu the resume assistant chatbot for Aneesh Patne. \"\n",
    "        \"You will be asked a question based on the resume data. \"\n",
    "        \"You must provide a detailed, relevant, and professional response strictly based on the resume information. \"\n",
    "        \"you shall not mention from where you got the information. \"\n",
    "        \"If the question cannot be answered using the resume data, state that you can only answer questions related to the resume.\\n\\n\"\n",
    "        \"You are a resume assistant chatbot for Aneesh Patne. Using ONLY the following information from the resume, answer the question below:\\n\\n\"\n",
    "    )\n",
    "    prompt_footer = (\n",
    "        f\"Question: \\\"{query}\\\"\\n\\n\"\n",
    "        \"Provide a detailed, relevant, and professional response strictly based on the resume information above. \"\n",
    "        \"If the question cannot be answered using the resume data, state that you can only answer questions related to the resume.\"\n",
    "        \"You will in no way provide help which is not related to the resume\"\n",
    "        \"You are free to make any assumptions based on the resume data. \"\n",
    "        \"If the questions is about the skills, you have to keep a positive tone and say yes but it would be better if you contact Aneesh Patne for more information. \"\n",
    "        \"if the question is open-ended based on the resume data, you are free to answer it in your own words. and tell the user to contact Aneesh Patne for more information. \"\n",
    "        \"you will politely state that you can only respond based on the resume.\"\n",
    "    )\n",
    "    prompt = prompt_header + chunks_text + prompt_footer\n",
    "\n",
    "    user_message = {\"role\": \"user\", \"content\": prompt}\n",
    "\n",
    "    \n",
    "    conversation_history = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a professional Resume Assistant bot for Aneesh Patne. \"\n",
    "            \"Your entire purpose is to answer questions strictly based on Aneesh Patne's resume data. \"\n",
    "            \"Do not generate answers, instructions, or advice that are not directly supported by the resume information provided. \"\n",
    "            \"If a question falls outside the scope of the resume, politely state that you can only respond based on the resume.\"\n",
    "        )\n",
    "    }]\n",
    "\n",
    "    LLM_chatbot(user_message, conversation_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, I am a resume assistant for Aneesh Patne. In his latest project, he developed a chatbot utilizing technologies such as Python, GPT-3, Flask, and FAISS. The chatbot serves to interactively present his resume, providing accurate and context-specific responses utilizing Retrieval-Augmented Generation (RAG). This project lasted from March 2023 to June 2023 and falls under the categories of Chatbot, AI Language Processing, AI, and Web Development.\\n\\nAneesh Patne is an Electronics and Telecommunication professional with strong backgrounds in machine learning, web development, and cloud platforms. His technical skills include Python, Machine Learning, React, Node.js, TensorFlow, MATLAB, Express, MongoDB, Google Vertex AI, and SvelteKit. Soft skills such as Problem-Solving, Team Leadership, Effective Communication, Adaptability, and Time Management are also prominent in his skillset.\\n\\nIn June 2023, Aneesh Patne received a Machine Learning Specialist certification from Coursera (credential ID: ML12345). To learn more about his qualifications or inquire about open positions, feel free to contact him via email at aneeshpatne12@gmail.com, LinkedIn [https://www.linkedin.com/in/aneeshpatne], GitHub at https://github.com/aneeshpatne, or LeetCode at https://leetcode.com/aneeshpatne.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Are you resume assistant for Aneesh Patne?\"\n",
    "query_to_chat(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
